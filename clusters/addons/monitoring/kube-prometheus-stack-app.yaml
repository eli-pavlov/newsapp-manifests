apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
  labels:
    # make sure PrometheusOperator treats this as managed (optional)
    app.kubernetes.io/managed-by: Helm
  annotations:
    # choose ordering relative to other apps; tune as you like
    argocd.argoproj.io/sync-wave: "-50"
spec:
  project: default
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    chart: kube-prometheus-stack
    targetRevision: 75.0.0
    helm:
      releaseName: kube-prometheus-stack
      values: |
        installCRDs: true
        ## Put minimal values here â€” adjust to taste
        global:
          rbac:
            create: true
          # set common nodeSelector if supported; otherwise per-component below
          # nodeSelector:
          #   role: control-plane

        ## Ensure pods schedule to control-plane nodes:
        prometheus:
          prometheusSpec:
            serviceMonitorSelector: {}            # accept ServiceMonitors regardless of labels
            serviceMonitorNamespaceSelector: {}   # empty object => select ALL namespaces
            podMonitorSelector: {}
            podMonitorNamespaceSelector: {}
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: ""
                  resources:
                    requests:
                      storage: 8Gi          

            nodeSelector:
              "node-role.kubernetes.io/control-plane": "true"
            tolerations:
              - key: "node-role.kubernetes.io/control-plane"
                operator: "Exists"
                effect: "NoSchedule"
            
            # reduce resource usage to be conservative on control-plane
            resources:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                cpu: 300m
                memory: 512Mi

        alertmanager:
          nodeSelector:
            "node-role.kubernetes.io/control-plane": "true"
          tolerations:
            - key: "node-role.kubernetes.io/control-plane"
              operator: "Exists"
              effect: "NoSchedule"
          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi

        grafana:
          enabled: true
          nodeSelector:
            "node-role.kubernetes.io/control-plane": "true"
          tolerations:
            - key: "node-role.kubernetes.io/control-plane"
              operator: "Exists"
              effect: "NoSchedule"
          persistence:
            enabled: false   # change to true and configure PVC if you want persistent dashboards
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 256Mi
          ingress:
            enabled: true
            ingressClassName: nginx
            ## Use annotations needed by ingress controller and cert-manager:
            annotations:
              kubernetes.io/ingress.class: "nginx"
              # choose one of the two cluster-issuer annotations:
              # For testing (staging):
              # cert-manager.io/cluster-issuer: "letsencrypt-staging"
              # For production:
              cert-manager.io/cluster-issuer: "letsencrypt-staging"
            hosts:
              - grafana.weblightenment.com
            # optional single-path config (chart may use this instead of nested host maps)
            path: /
            pathType: Prefix
            tls:
              - hosts:
                  - grafana.weblightenment.com
                secretName: grafana-tls

        kubeStateMetrics:
          resources:
            requests:
              cpu: 20m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi

        nodeExporter:
          enabled: false  # node exporter on control-plane can be enabled, but may duplicate cluster metrics

        # optionally disable ServiceMonitors you don't need to reduce resource usage
        prometheusOperator:
          enabled: true

  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ApplyOutOfSyncOnly=true
